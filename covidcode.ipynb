{      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-43zi6pJmJt9"
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szGiUbHEmK0t"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrthQ5TymQ-O"
      },
      "source": [
        "# Importing libraries\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "#import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras import utils as np_utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation,BatchNormalization\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import keras\n",
        "import numpy as np\n",
        "import scipy\n",
        "import sklearn\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dense, Dropout, Activation\n",
        "#from keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Embedding\n",
        "#from keras.utils import np_utils\n",
        "#from tensorflow.keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot\n",
        "print(__doc__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Input\n",
        "from tensorflow.keras import backend as K\n",
        "#from tensorflow.keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, ReLU\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVR\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from  tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
		"from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "GOOGLE_COLAB = True\n",
        "TRAINING_LOGS_FILE = \"training_logs.csv\"\n",
        "MODEL_SUMMARY_FILE = \"model_summary.txt\"\n",
        "TEST_FILE = \"test_file.txt\"\n",
        "MODEL_FILE = \"model.h0\"\n",
        "if GOOGLE_COLAB:\n",
        "    !pip install livelossplot\n",
        "from livelossplot import PlotLossesKeras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxlwJzsSmWhu"
      },
      "source": [
        "!unzip drive/c_b_covid_fold5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcR7StupmhPW"
      },
      "source": [
        "training_data_dir =\"c_b_covid_fold5/train\" \n",
        "validation_data_dir = \"c_b_covid_fold5/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC6OWkIWmmd0"
      },
      "source": [
        "# Hyperparams\n",
        "IMAGE_SIZE = 224\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT = IMAGE_SIZE, IMAGE_SIZE\n",
        "EPOCHS =30\n",
        "BATCH_SIZE =3\n",
        "TEST_SIZE = 3\n",
        "learning = 0.00001\n",
        "\n",
        "input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE1kDqry_Rov"
      },
      "source": [
        "#InceptionV3\n",
        "\n",
        "#import libraries\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras import Sequential\n",
        "#import numpy\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "#from tensorflow.keras.layers import Dense, Dropout, Activation,BatchNormalization\n",
        "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "#import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "#%matplotlib inline\n",
        "\n",
        "#load pre trained Xception model\n",
        "base_model=tf.keras.applications.inception_v3.InceptionV3(weights='imagenet',include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        " #and a logistic layer -- let's say we have 200 classes\n",
        "\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "#x=Dense(4)(x)\n",
        "#Activation(tf.nn.softmax)\n",
        "#predictions = x \n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=Adam(lr=learning, beta_1=0.9, beta_2=0.999, amsgrad=False), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#Summary of Xception Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BV4jqoOH4ee"
      },
      "source": [
        "#ResNet50\n",
        "\n",
        "#import libraries\n",
        "\n",
        "#import libraries\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras import Sequential\n",
        "#import numpy\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "#from tensorflow.keras.layers import Dense, Dropout, Activation,BatchNormalization\n",
        "#from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "#import matplotlib.pyplot as plt\n",
        "#import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "%matplotlib inline\n",
        "\n",
        "#load pre trained Xception model\n",
        "base_model=tf.keras.applications.ResNet50(weights='imagenet',include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        " #and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "#x=Dense(4)(x)\n",
        "#Activation(tf.nn.softmax)(x)\n",
        "#predictions = x \n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=Adam(lr=learning, beta_1=0.9, beta_2=0.999, amsgrad=False), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#Summary of Xception Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVQsQ2J58PVx"
      },
      "source": [
        "#ResNet101\n",
        "\n",
        "#import libraries\n",
        "from tensorflow.python.keras.applications.resnet import ResNet101\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras import Sequential\n",
        "%matplotlib inline\n",
        "\n",
        "#load pre trained Xception model\n",
        "base_model=tf.keras.applications.resnet.ResNet101(include_top=True, weights='imagenet')\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        " #and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "#x=Dense(4)(x)\n",
        "#Activation(tf.nn.softmax)(x)\n",
        "#predictions = x \n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=Adam(lr=learning, beta_1=0.9, beta_2=0.999, amsgrad=False), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#Summary of Xception Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEgDYqK5CWcX"
      },
      "source": [
        "#ResNet152\n",
        "\n",
        "#import libraries\n",
        "from tensorflow.python.keras.applications.resnet import ResNet152\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras import Sequential\n",
        "%matplotlib inline\n",
        "\n",
        "#load pre trained Xception model\n",
        "base_model=tf.keras.applications.resnet.ResNet152(include_top=True, weights='imagenet')\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        " #and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "#x=Dense(4)(x)\n",
        "#Activation(tf.nn.softmax)(x)\n",
        "#predictions = x \n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=Adam(lr=learning, beta_1=0.9, beta_2=0.999, amsgrad=False), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#Summary of Xception Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2lTL-qqSJp5"
      },
      "source": [
        "#InceptionResNetV2\n",
        "\n",
        "#import libraries\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "%matplotlib inline\n",
        "\n",
        "#load pre trained Xception model\n",
        "base_model=InceptionResNetV2(weights='imagenet',include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        " #and a logistic layer -- let's say we have 200 classes\n",
        "predictions = Dense(2, activation='softmax')(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# first: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer=Adam(lr=learning, beta_1=0.9, beta_2=0.999, amsgrad=False), loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "#Summary of Xception Model\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T-uI52smshp"
      },
      "source": [
        "with open(MODEL_SUMMARY_FILE,\"w\") as fh:\n",
        "    model.summary(print_fn=lambda line: fh.write(line + \"\\n\"))\n",
        "\n",
        "# Data augmentation\n",
        "training_data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "validation_data_generator = ImageDataGenerator(rescale=1./255)\n",
        "test_data_generator = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0MgADP6myAI"
      },
      "source": [
        "# Data preparation\n",
        "training_generator = training_data_generator.flow_from_directory(\n",
        "    training_data_dir,\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\")\n",
        "validation_generator = validation_data_generator.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZNFb-Dem1xJ"
      },
      "source": [
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "csv_logger = CSVLogger('training_log.csv')\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Training\n",
        "H = model.fit_generator(\n",
        "    training_generator,\n",
        "    steps_per_epoch=len(training_generator.filenames) // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator.filenames) // BATCH_SIZE,\n",
        "    callbacks=[csv_logger])\n",
        "\n",
        "#model.save_weights(MODEL_FILE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iihIf1etrRdB"
      },
      "source": [
        "N = EPOCHS\n",
        "plt.style.use(\"seaborn-white\")\n",
        "plt.figure(dpi=600)\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"test_loss\")\n",
        "plt.title(\"Training Loss\",fontsize=14)\n",
        "plt.xlabel(\"Epoch\",fontsize=14)\n",
        "plt.ylabel(\"Loss\",fontsize=14)\n",
        "plt.legend(loc=\"upper right\",fontsize=14)\n",
        "plt.savefig(\"plot.png\")\n",
        "\n",
        "plt.style.use(\"seaborn-white\")\n",
        "plt.figure(dpi=600)\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"test_acc\")\n",
        "plt.title(\"Training Accuracy\",fontsize=14)\n",
        "plt.xlabel(\"Epoch\",fontsize=14)\n",
        "plt.ylabel(\"Accuracy\",fontsize=14)\n",
        "plt.legend(loc=\"lower right\",fontsize=14)\n",
        "plt.savefig(\"plot.png\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZruqSJhZ5GOD"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "LABELS = [\"Bacterial\",\"Covid-19\"]\n",
        "\n",
        "def show_confusion_matrix(validations, predictions):\n",
        "    matrix = confusion_matrix(validations, predictions)\n",
        "    plt.figure(figsize=(8, 8), dpi=600)\n",
        "    sn.set(font_scale=1.6)#for label size\n",
        "    sns.heatmap(matrix,\n",
        "                cmap=\"coolwarm\",\n",
        "                linecolor='white',\n",
        "                linewidths=1,\n",
        "                xticklabels=LABELS,\n",
        "                yticklabels=LABELS,\n",
        "                annot=True,\n",
        "                fmt=\"d\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.show()\n",
        "\n",
        "validation_generator = validation_data_generator.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=False)    \n",
        "\n",
        "filenames = validation_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "\n",
        "Y_pred = model.predict_generator(validation_generator,(nb_samples//BATCH_SIZE)+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "show_confusion_matrix(validation_generator.classes, y_pred)\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names =[\"covid\",\"bacterial\"]\n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
        "sn.set(font_scale=1.4)#for label size\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKt9wC6px8ps"
      },
      "source": [
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import cycle\n",
        "plt.style.use(\"seaborn-white\")\n",
        "y_test = label_binarize(validation_generator.classes, classes=[0, 1])\n",
        "y_pred= label_binarize(y_pred, classes=[0, 1])\n",
        "# Plot linewidth.\n",
        "lw = 2\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(1):\n",
        "   fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_pred[:,i])\n",
        "   roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "plt.style.use(\"seaborn-white\")\n",
        "\n",
        "plt.figure(dpi=600)\n",
        "lw = 2\n",
        "plt.plot(fpr[i], tpr[i], color='darkorange',\n",
        "       lw=lw, label='ROC curve (area = %0.4f)' % roc_auc[i])\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([-0.01, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate',fontsize=14)\n",
        "plt.ylabel('True Positive Rate',fontsize=14)\n",
        "plt.legend(loc=\"lower right\",fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(2)\n",
        "colors = cycle(['darkmagenta', 'darkorange', 'darkblue'])\n",
        "for i, color in zip(range(1), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "             ''.format(i, roc_auc[i]))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "plt.xlim([-0.01, 1.0])\n",
        "plt.ylim([-0.05, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic to multi-class')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
